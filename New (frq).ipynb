{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f794d4c",
   "metadata": {},
   "source": [
    "# Cars 4 You: Expending Car Evaluations with ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f35cae",
   "metadata": {},
   "source": [
    "## 1. Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c97d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import make_scorer \n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df3cfc",
   "metadata": {},
   "source": [
    "## 2. Data importation and integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('project_data/train.csv')\n",
    "test_data = pd.read_csv('project_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0654bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= train_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ae41d5",
   "metadata": {},
   "source": [
    "## 3. Data exploration and understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6010fb",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "- *carID*: An attribute that contains an identifier for each car.\n",
    "- *Brand*: The car’s main brand (e.g. Ford, Toyota).\n",
    "- *model*: The car model.\n",
    "- *year*: The year of Registration of the Car.\n",
    "- *mileage*: The total reported distance travelled by the car (in\n",
    " miles).\n",
    "- *tax*: The amount of road tax (in £) that, in 2020, was\n",
    " applicable to the car in question.\n",
    "- *fuelType*: Type of Fuel used by the car (Diesel, Petrol, Hybrid,\n",
    " Electric).\n",
    "- *mpg*: Average Miles per Gallon.\n",
    "- *engineSize*: Size of Engine in liters (Cubic Decimeters).\n",
    "- *paintQuality%*:  The mechanic’s assessment of the cars’ overall paint\n",
    " quality and hull integrity (filled by the mechanic\n",
    " during evaluation). \n",
    "- *previousOwners*: Number of previous registered owners of the vehicle.\n",
    "- *hasDamage*:  Boolean marker filled by the seller at the time of\n",
    " registration stating whether the car is damaged or\n",
    " not.\n",
    "- *price*: The car’s price when purchased by Cars 4 You (in £)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9aaa3",
   "metadata": {},
   "source": [
    "### 3.1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d371b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eaa0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first 20 rows\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91671e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 20 rows\n",
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd69846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for numerical data\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for categorical data\n",
    "data.describe(include = ['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate numerical and categorical features \n",
    "\n",
    "metric_features = ['year', 'mileage', 'tax', 'mpg',\n",
    "                    'engineSize', 'paintQuality%', 'previousOwners', 'hasDamage']\n",
    "\n",
    "non_metric_features= ['Brand','model','transmission','fuelType']\n",
    "\n",
    "identifier = 'carID'\n",
    "\n",
    "target = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ef78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking what are the unique values of categorical variables\n",
    "for col in non_metric_features:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e276a877",
   "metadata": {},
   "source": [
    "### 3.2. Checking Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081ba1f",
   "metadata": {},
   "source": [
    "### 3.3. Checking Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc40889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of missing values in each column as a percentage\n",
    "data.isna().sum()/len(data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cccf56f",
   "metadata": {},
   "source": [
    "### 3.4. Checking Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers of numerical variables through the visualization of boxplots\n",
    "\n",
    "def plot_multiple_boxplots(data, feats, title=\"Numeric Variables' Box Plots\"):\n",
    "\n",
    "    # Prepare figure. Create individual axes where each histogram will be placed\n",
    "    fig, axes = plt.subplots(4, ceil(len(feats) / 4), figsize=(40, 30))\n",
    "\n",
    "    # Plot data\n",
    "    # Iterate across axes objects and associate each histogram:\n",
    "    for ax, feat in zip(axes.flatten(), feats):\n",
    "        sns.boxplot(x=data[feat], ax=ax, color=\"#5dade2\")\n",
    "        ax.set_title(feat)\n",
    "\n",
    "    # Layout\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_boxplots(data, metric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de90394",
   "metadata": {},
   "source": [
    "### 3.5. Checking Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(data[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histograms to see the distribrution of numerical variables\n",
    "\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "n = len(num_cols)\n",
    "\n",
    "# Adjust layout\n",
    "fig, axes = plt.subplots(nrows=(n // 3) + 1, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    axes[i].hist(df[col].dropna(), bins=20, color='#5dade2', edgecolor='black')  \n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('frequency')\n",
    "\n",
    "# Remove empty axes\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619f083",
   "metadata": {},
   "source": [
    "### 3.5. Checking Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating barplots to understand the categorical data\n",
    "\n",
    "sns.set_style('white')  \n",
    "sns.set_palette(['#5dade2'])  \n",
    "\n",
    "# Create 4 subplots stacked vertically\n",
    "fig, ax = plt.subplots(nrows=4, ncols=1, dpi=300, figsize=(20, 40))\n",
    "fig.patch.set_facecolor('white') \n",
    "\n",
    "# Plot each variable in its own row\n",
    "sns.countplot(data=test_data, x='Brand', ax=ax[0])\n",
    "sns.countplot(data=test_data, x='model', ax=ax[1])\n",
    "sns.countplot(data=test_data, x='transmission', ax=ax[2])\n",
    "sns.countplot(data=test_data, x='fuelType', ax=ax[3])\n",
    "\n",
    "# Improve spacing between plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031363e6",
   "metadata": {},
   "source": [
    "### 3.6. Checking Correlation between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa615f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between variables \n",
    "# We are going to use spearman correlation since our variables do not follow a normal distribution\n",
    "cor_spearman = data[metric_features].corr(method ='spearman')\n",
    "cor_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix to facilitate interpretation\n",
    "\n",
    "def cor_heatmap(cor):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Create a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(cor, dtype=bool))\n",
    "\n",
    "    # Plot heatmap \n",
    "    sns.heatmap(\n",
    "        data=cor,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        cmap='YlGnBu',   \n",
    "        fmt='.2f',\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "    )\n",
    "\n",
    "    plt.title(\"Spearman Correlation Matrix\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_heatmap(cor_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise Relationship of Numerical Variables\n",
    "sns.set()\n",
    "\n",
    "# Setting pairplot and use historgrams in the diagonal\n",
    "sns.pairplot(df[metric_features], diag_kind=\"hist\")\n",
    "\n",
    "# Layout\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.suptitle(\"Pairwise Relationship of Numerical Variables\", fontsize=20)\n",
    "\n",
    "# Create eda directory \n",
    "if not os.path.exists(os.path.join('..', 'figures', 'eda')):\n",
    "    os.makedirs(os.path.join('..', 'figures', 'eda'))\n",
    "    \n",
    "plt.savefig(os.path.join('..', 'figures', 'eda', 'pairwise_numeric_scatterplots.png'), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127253f3",
   "metadata": {},
   "source": [
    "## 4. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0b97d",
   "metadata": {},
   "source": [
    "### 4.1. Set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53343982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to CarID as each car has its own unique identifier\n",
    "data.set_index('carID', inplace = True)\n",
    "test_data.set_index('carID', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea4c33",
   "metadata": {},
   "source": [
    "### 4.2. Slipt the data into train and validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5323aa",
   "metadata": {},
   "source": [
    "#### The Hold Out Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('price', axis = 1) # In X, the target variable will be removed and the dataset will be used as the training set\n",
    "y = data['price']  # y corresponds to the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8157620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the dataset\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.3,  # 30% will be used for validation \n",
    "                                                  random_state = 0,      # Ensures the split is always the same every time the code runs\n",
    "                                                  shuffle = True)        # Shuffles the data before spliting to avoid bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675beabd",
   "metadata": {},
   "source": [
    "### 4.3. Changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounds the floats and changes them to integers\n",
    "\n",
    "#year to integer\n",
    "X_train['year'] = X_train['year'].round().astype('Int32')\n",
    "X_val['year'] = X_val['year'].round().astype('Int32')\n",
    "test_data['year'] = test_data['year'].round().astype('Int32')\n",
    "\n",
    "#previousOwners to integer\n",
    "X_train['previousOwners'] = X_train['previousOwners'].round().astype('Int32')\n",
    "X_val['previousOwners'] = X_val['previousOwners'].round().astype('Int32')\n",
    "test_data['previousOwners'] = test_data['previousOwners'].round().astype('Int32')\n",
    "\n",
    "#hasDamaged to boolean\n",
    "X_train['hasDamage'] = X_train['hasDamage'].astype('Int8')\n",
    "X_val['hasDamage'] = X_val['hasDamage'].astype('Int8')\n",
    "test_data['hasDamage'] = test_data['hasDamage'].astype('Int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42028c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56035209",
   "metadata": {},
   "source": [
    "### 4.4. Handling Incoherencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d48b2",
   "metadata": {},
   "source": [
    "#### 4.4.1. Categorical Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec5176",
   "metadata": {},
   "source": [
    "##### 4.4.1.1. Correcting Spelling Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e207cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##correcting spelling mistakes of 'brand' for X_train, X_val and test_data\n",
    "\n",
    "correct_brand = {\n",
    "    'VW': ['V', 'vw', 'v', 'W', 'w'],\n",
    "    'Toyota': ['Toyot', 'TOYOTA', 'oyota', 'toyota', 'OYOTA', 'TOYOT', 'toyot', 'oyot'],\n",
    "    'Audi': ['udi', 'AUDI', 'audi', 'Aud', 'aud', 'UDI', 'AUD'],\n",
    "    'Ford': ['FOR', 'ord', 'For', 'FORD', 'ford', 'for', 'or', 'ORD'],\n",
    "    'BMW': ['MW', 'bmw', 'BM', 'mw', 'M', 'bm'],\n",
    "    'Skoda': ['koda', 'skoda', 'SKODA', 'Skod', 'kod', 'SKOD', 'KODA', 'skod'],\n",
    "    'Opel': ['Ope', 'opel', 'pel', 'pe', 'OPEL', 'PEL', 'OPE', 'ope'],\n",
    "    'Mercedes': ['mercedes', 'Mercede', 'MERCEDES', 'ercedes', 'mercede', 'ERCEDES', 'ercede', 'MERCEDE'],\n",
    "    'Hyundai': ['yundai', 'Hyunda', 'hyundai', 'HYUNDAI', 'yunda', 'HYUNDA', 'ud', 'hyunda', 'YUNDAI']\n",
    "}\n",
    "\n",
    "# Create a reverse lookup dictionary (each incorrect form maps to the correct one)\n",
    "replacement_dict = {variant: correct for correct, variants in correct_brand.items() for variant in variants}\n",
    "\n",
    "# Replace incorrect brand names with the correct ones\n",
    "X_train[\"Brand\"] = X_train[\"Brand\"].replace(replacement_dict)\n",
    "X_val[\"Brand\"] = X_val[\"Brand\"].replace(replacement_dict)\n",
    "test_data[\"Brand\"] = test_data[\"Brand\"].replace(replacement_dict)\n",
    "\n",
    "# Verify the cleaning\n",
    "print(X_train[\"Brand\"].unique())\n",
    "print(X_val[\"Brand\"].unique())\n",
    "print(test_data[\"Brand\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be84777",
   "metadata": {},
   "outputs": [],
   "source": [
    "##correcting spelling mistakes of 'model' for X_train, X_val and test_data\n",
    "\n",
    "correct_model = {\n",
    "    'Golf': [' GOLF', ' Gol', ' golf', 'golf', ' Golf', ' gol', ' GOL', 'Gol', 'GOLF'],\n",
    "    'Yaris': [' Yaris', ' YARIS', ' Yari', ' yaris', ' yari', 'Yari', ' YARI', 'yaris', 'YARIS'],\n",
    "    'Q2': [' q2', ' Q2'],\n",
    "    '2 Series': [' 2 series', ' 2 serie', '2 Series', ' 2 SERIES', ' 2 Serie', '2 Serie', ' 2 Series'],\n",
    "    '3 Series': [' 3 Series', ' 3 Serie', ' 3 series', ' 3 SERIES', ' 3 serie', '3 Serie'],\n",
    "    'A3': [' A3', ' a3'],\n",
    "    'Octavia': [' Octavi', ' OCTAVIA', ' Octavia', ' octavia', 'Octavi', 'octavia', ' octavi', ' OCTAVI'],\n",
    "    'Passat': [' PASSAT', ' passat', ' Passa', 'Passat', ' Passat', 'PASSAT', ' PASSA'],\n",
    "    'Insignia': [' Insigni', ' INSIGNIA', ' insignia', ' Insignia', ' INSIGNI', 'Insigni'],\n",
    "    'Fabia': [' Fabia', ' fabia', ' FABIA', ' Fabi', 'FABIA'],\n",
    "    'A Class': [' A Clas', ' A Class', ' a class', ' A CLASS', 'a class', 'A CLASS', ' a clas'],\n",
    "    'Ka+': [' Ka+', ' KA+', ' ka+', 'ka+'],\n",
    "    'GLC Class': [' GLC Class', ' GLC CLASS', ' GLC Clas', ' glc class', ' glc clas'], \n",
    "    'I30': [' i30', ' I30'],\n",
    "    'C Class': [' C Clas', ' C CLASS', ' c class', 'C Clas', ' C CLAS', 'c class', ' c clas', ' C Class', 'C CLASS'],\n",
    "    'Polo': [' POLO', ' Polo', ' polo', ' Pol', ' POL', 'Pol', 'POLO'],\n",
    "    'E Class': [' E Class', ' E Clas', ' E CLASS', ' e class', 'E CLASS', 'e class'],\n",
    "    'Q5': [' Q5', ' q5', 'q5'],\n",
    "    'Up': ['U', ' up', ' UP', ' Up', ' U', 'UP'],\n",
    "    'Fiesta': [' FIESTA', ' fiesta', ' Fiest', ' Fiesta', 'fiesta', 'Fiest', ' FIESTA', 'FIESTA', ' fiest'],\n",
    "    'C-HR': [' C-H', ' c-hr', ' C-HR', ' c-h'],\n",
    "    'Mokka X': [' mokka x', ' MOKKA X', ' Mokka X'],\n",
    "    'Corsa': [' Corsa', ' corsa', ' Cors', ' CORSA', ' cors', ' CORS', 'corsa'],\n",
    "    'Astra': [' ASTRA', ' Astr', ' Astra', ' astra', 'ASTRA', 'astra'],\n",
    "    'TT': [' tt', ' TT', ' T'],\n",
    "    '5 Series': [' 5 Series', ' 5 Serie', ' 5 SERIES', ' 5 series', '5 SERIES', ' 5 SERIE'],\n",
    "    'Aygo': [' aygo', ' ayg', ' AYGO', ' Ayg', ' Aygo', 'aygo', ' AYG'],\n",
    "    '4 Series': [' 4 SERIES', ' 4 Serie', ' 4 serie', '4 series', '4 Series', ' 4 Series', ' 4 series'],\n",
    "    'SLK': [' slk', ' SLK'],\n",
    "    'Viva': [' viva', ' Viva', ' VIVA', ' Viv', 'viva'],\n",
    "    'Focus': [' Focus', ' Focu', ' FOCUS', ' focus', ' FOCU', 'focus', 'Focu', ' focu', 'FOCUS'],\n",
    "    'EcoSport': [' EcoSpor', ' ECOSPORT', ' ecosport', ' EcoSport'],\n",
    "    'X-CLASS': [' x-clas', ' X-CLAS', ' x-class', ' X-CLASS'],\n",
    "    'CL Class': [' cl class', ' CL Clas', ' CL CLASS', ' CL Class'],\n",
    "    'IX20': [' ix20', ' IX20'],\n",
    "    'Rapid': [' Rapi', ' rapid', ' Rapid'],\n",
    "    'Auris': [' Auris', ' AURIS', ' auris', ' Auri'],\n",
    "    'I20': [' i20', ' I20'],\n",
    "    'X3': [' x3', ' X3'],\n",
    "    'A8': [' A8', 'a8'],\n",
    "    'GLS Class': [' GLS Clas', ' GLS CLASS', ' gls class', ' GLS Class'],\n",
    "    'B-MAX': [' B-MA', ' B-MAX', 'B-MA', ' b-max'],\n",
    "    'A4': [' A4', ' a4'],\n",
    "    'Kona': [' KONA', ' Kon', ' Kona', ' KON', ' kona'],\n",
    "    'I10': [' i10', ' I10'],\n",
    "    'A1': [' A1', ' a1'],\n",
    "    'Mokka': [' Mokka ', ' Mokk', ' Mokka', ' mokka ', ' mokka', ' MOKKA', 'Mokka ', 'Mokk'],\n",
    "    'S-MAX': [' S-MA', ' s-max', ' S-MAX', ' s-ma'],\n",
    "    'X2': [' x2', ' X2'],\n",
    "    'Crossland X': [' crossland x', ' CROSSLAND X', ' Crossland X'],\n",
    "    'Tiguan': [' Tiguan', ' tiguan', ' Tigua', ' TIGUAN', ' TIGUA', 'Tigua', 'TIGUAN', 'tiguan', ' tigua'],\n",
    "    'A5': [' A5', ' a5', 'a5'],\n",
    "    'GLE Class': [' GLE Clas', ' GLE Class', ' gle class', ' GLE CLASS'],\n",
    "    'Zafira': [' Zafira', ' Zafir', ' ZAFIRA', ' zafira', 'Zafir', ' ZAFIR'],\n",
    "    'Ioniq': [' Ioni', ' Ioniq', ' IONIQ', 'IONIQ', ' ioniq'],\n",
    "    'A6': [' A6', ' a6'],\n",
    "    'Yeti Outdoor': [' yeti outdoor', ' Yeti Outdoor', ' YETI OUTDOOR', ' Yeti Outdoo', ' yeti outdoor', 'yeti outdoor', ' yeti outdoo'],\n",
    "    'X1': [' x1', 'x1', ' X1'],\n",
    "    'Scala': [' SCALA', ' Scala', ' scala', ' Scal', ' scal'],\n",
    "    'S Class': [' S Class', ' S Clas', ' s class', ' S CLASS'],\n",
    "    '1 Series': [' 1 Series', ' 1 SERIES', ' 1 Serie', ' 1 series', '1 SERIES', ' 1 SERIE', '1 series', ' 1 serie'],\n",
    "    'Kamiq': [' KAMIQ', ' KAMI', ' kamiq', ' Kamiq'],\n",
    "    'Kuga': [' Kug', ' KUGA', ' kuga', 'Kuga', ' Kuga', 'kuga'],\n",
    "    'Tourneo Connect': [' tourneo connect', ' Tourneo Connect'],\n",
    "    'Q7': [' q7', ' Q7'],\n",
    "    'GLA Class': [' GLA Class', ' GLA CLASS', ' GLA Clas', ' gla class'],\n",
    "    'Arteon': [' arteon', ' Arteon', ' Arteon'],\n",
    "    'SL CLASS': [' SL CLAS', ' SL CLASS', ' sl class', ' SL'],\n",
    "    'Tucson': [' Tucson', ' TUCSON', ' Tucso', ' tucson', ' TUCSO', 'Tucso'],\n",
    "    'Santa Fe': [' Santa F', ' santa fe', ' SANTA FE', ' Santa Fe'],\n",
    "    'Grandland X': [' Grandland X', ' grandland x', ' GRANDLAND X'],\n",
    "    'RAV4': [' rav4', 'RAV4', 'RAV', ' RAV', 'rav4', ' rav', ' RAV4'],\n",
    "    'Touran': [' Touran', 'Toura', ' TOURAN', ' touran', ' Toura', ' TOURA'],\n",
    "    'Citigo': [' Citig', ' citigo', ' Citigo', ' CITIGO', 'CITIGO'],\n",
    "    'Roomster': [' Roomste', ' Roomster'],\n",
    "    'Prius': [' PRIUS', ' Prius', 'Prius', ' prius'],\n",
    "    'Corolla': [' corolla', ' COROLLA', ' Coroll', ' Corolla', 'corolla'],\n",
    "    'B Class': [' b class', ' B Clas', ' B Class', ' B CLASS', 'b class'],\n",
    "    'Sharan': [' sharan', ' Shara', ' Sharan', ' SHARAN'],\n",
    "    'Kodiaq': [' Kodia', ' kodiaq', 'kodiaq', ' KODIAQ', ' Kodiaq'],\n",
    "    'V Class': [' V Clas', ' V CLASS', ' V Class', ' v class'],\n",
    "    'Caddy Maxi Life': [' Caddy Maxi Lif', ' Caddy Maxi Life'],\n",
    "    'Superb': [' Superb', ' Super', ' SUPERB', ' superb', ' super'],\n",
    "    'T-Roc': [' T-Roc', ' T-RO', ' t-roc', ' T-Ro', ' T-ROC'],\n",
    "    'Combo Life': [' COMBO LIFE', ' combo life', ' Combo Lif', 'COMBO LIFE', ' Combo Life'],\n",
    "    'Beetle': [' Beetl', ' Beetle', ' beetle'],\n",
    "    'Galaxy': [' GALAXY', ' Galax', ' galaxy', ' Galaxy'],\n",
    "    'M3': [' M3', ' m3'],\n",
    "    'Gtc': [' gtc', ' GTC', ' gtc', 'gtc', 'GTC'],\n",
    "    'X4': [' X4', ' x4'],\n",
    "    'KA': [' Ka', ' ka', ' K', ' KA'],\n",
    "    'IX35': [' ix35', ' IX35'],\n",
    "    'Grand Tourneo Connect': [' Grand Tourneo Connec', ' Grand Tourneo Connect'],\n",
    "    'M4': [' m4', ' M4'],\n",
    "    'Tourneo Custom': [' tourneo custom', ' Tourneo Custo', ' Tourneo Custom'],\n",
    "    'Z4': [' Z4', ' z4'],\n",
    "    'X5': [' X5', ' x5'],\n",
    "    'Meriva': [' Meriva', ' MERIVA', ' Meriv', ' meriva'],\n",
    "    'RS6': [' RS6'],\n",
    "    'Verso': [' VERSO', ' verso', ' Verso', ' Vers'],\n",
    "    'Touareg': [' Touareg', ' TOUAREG', ' touareg', ' Touare'],\n",
    "    'Mondeo': [' MONDEO', ' Mondeo', ' mondeo', ' MONDE', ' Monde'],\n",
    "    'Shuttle': [' shuttle', ' Shuttle', ' SHUTTLE'],\n",
    "    'CLS Class': [' CLS Class', ' cls class', ' CLS Clas', ' CLS CLASS'], \n",
    "    'C-MAX': [' C-MAX', ' c-max', ' C-MA'],\n",
    "    'Puma': [' puma', ' PUMA', ' Puma', 'Pum', ' Pum'],\n",
    "    'CLA Class': [' CLA Class', ' CLA CLASS', ' cla class', ' CLA Clas'],\n",
    "    'I40': [' I40', ' i40'],\n",
    "    'Q3': [' q3', ' Q3'],\n",
    "    'Tiguan Allspace': [' TIGUAN ALLSPACE', ' tiguan allspace', ' Tiguan Allspac', ' Tiguan Allspace'],\n",
    "    '6 Series': [' 6 SERIES', ' 6 series', ' 6 Series', ' 6 Serie'],\n",
    "    'Caravelle': [' caravelle', ' Caravell', ' Caravelle'],\n",
    "    'Karoq': [' Karoq', ' karoq', ' KAROQ', ' Karo'],\n",
    "    'I3': [' i3', 'i3', ' I3'],\n",
    "    'Grand C-MAX': [' GRAND C-MAX', ' grand c-max', ' Grand C-MA', ' Grand C-MAX'],\n",
    "    'T-Cross': [' T-Cros', ' T-CROSS', ' T-Cross', ' t-cros', ' t-cross'],\n",
    "    'A7': [' a7', ' A7'],\n",
    "    'Golf SV': [' Golf SV', ' golf sv', ' GOLF SV'],\n",
    "    'A': [' a', ' A'],\n",
    "    'GT86': [' gt86', ' GT86'],\n",
    "    'Yeti': [' yeti', ' Yet', ' Yeti', ' YETI'],\n",
    "    'X': [' x', ' X'],\n",
    "    'Land Cruiser': [' Land Cruise', ' Land Cruiser', ' land cruiser'],\n",
    "    'EDGE': [' Edge', ' edge', ' Edg', ' EDGE'],\n",
    "    'X6': [' X6'],\n",
    "    'Fusion': [' Fusion', ' fusion'],\n",
    "    'GL Class': [' GL CLASS', ' gl class', ' GL Class', ' GL Clas'],\n",
    "    'Scirocco': [' scirocco', ' SCIROCCO', ' Scirocc', ' Scirocco'],\n",
    "    'Z3': [' Z3'],\n",
    "    'Hilux': [' hilux', ' Hilux', ' Hilu', ' HILU'],\n",
    "    'Amarok': [' amarok', ' Amarok', ' Amaro'],\n",
    "    'CC': [' cc', ' CC'],\n",
    "    '7 Series': [' 7 Serie', ' 7 SERIES', ' 7 series', ' 7 Series'],\n",
    "    'Avensis': [' AVENSIS', ' avensis', ' Avensis'],\n",
    "    'M Class': [' m class', ' M CLASS', ' M Class', ' M Clas', ' M CLAS'],\n",
    "    'Grandland': [' grandland ', ' Grandland '],\n",
    "    'Zafira Tourer': [' Zafira Toure', ' ZAFIRA TOURER', ' Zafira Tourer', ' zafira tourer'],\n",
    "    'R8': [' R8', ' r8'],\n",
    "    'Mustang': [' mustang', ' Mustang'],\n",
    "    'Q8': [' Q8'],\n",
    "    'CLK': [' CLK'],\n",
    "    'RS3': [' RS3'],\n",
    "    'Jetta': [' JETTA', ' Jetta', ' jetta', 'Jetta' ],\n",
    "    'Supra': [' Supra'],\n",
    "    'X7': [' X7'],\n",
    "    'SQ7': [' SQ7', ' sq7'],\n",
    "    'S3': [' s3', ' S3'],\n",
    "    'Arteon': [' Arteo', 'Arteo', ' ARTEON', ' arteon', ' Arteon'],\n",
    "    'GLB Class': [' glb class', ' GLB Class'],\n",
    "    'Adam': [' Ada', ' adam', ' ADAM', ' Adam'],\n",
    "    'M5': [' M5',' m5'],\n",
    "    'Golf S': [' golf s', ' Golf S'],\n",
    "    'Vectra': ['Vectra', ' Vectra', ' VECTRA', 'VECTRA'],\n",
    "    '8 Series': [' 8 SERIES', ' 8 Serie', ' 8 Series', ' 8 series'],\n",
    "    'Urban Cruiser': [' Urban Cruise', ' Urban Cruiser'],\n",
    "    'Fox': ['fox', ' fox', ' Fox'], \n",
    "    'Q': [' Q'], \n",
    "    'M2': [' M2'], \n",
    "    'RS4':[' RS4'], \n",
    "    'Veloster': [' Veloster', ' Veloste'],  \n",
    "    'IQ': [' IQ'], \n",
    "    'Agila': [' AGILA', ' Agila'], \n",
    "    'I2': [' I2'], \n",
    "    'Antara': [' Antara', ' antara'], \n",
    "    'G Class': [' G Class', ' G CLAS'], \n",
    "    'Caddy Life': [' Caddy Life', ' Caddy'],\n",
    "    'R Class': [' R Class'], \n",
    "    'I800': [' I800'],\n",
    "    'Amica': [' Amica'], \n",
    "    'Crossland': [' Crossland '],\n",
    "    'Proace Verso': [' proace verso', ' PROACE VERSO', 'PROACE VERSO'],\n",
    "    'Camry': [' Camry', 'Camry', ' Camr'], \n",
    "    'Tigra': [' Tigra'], \n",
    "    'Eos': [' Eos'], \n",
    "    'M': [' M'],\n",
    "    'California': [' Californi', ' California'], \n",
    "    'Ampera': [' Ampera'], \n",
    "    'I1': [' I1'], \n",
    "    'S5': [' S5'], \n",
    "    'CLC Class': [' CLC Class'], \n",
    "    'Shara': [' SHARA'], \n",
    "    'I8': [' i8', 'i8'], \n",
    "    'RS7': [' RS7'], \n",
    "    'Transit Tourneo': [' Transit Tourneo'], \n",
    "    'I4': [' I4'], \n",
    "    'S4':[' S4'], \n",
    "    'Terracan': [' Terracan'], \n",
    "    'Cascada': [' Cascada'], \n",
    "    'S8': [' S8'], \n",
    "    'A2':[' A2'], \n",
    "    'Vivaro':[' Vivaro'],\n",
    "    'RS5':[' RS5'],\n",
    "    'SQ5':[' SQ5'], \n",
    "    'Getz':[' Getz'], \n",
    "    'M6':[' M6'], \n",
    "    'Caddy Maxi': [' Caddy Maxi'], \n",
    "    'Z':[' Z'], \n",
    "    'Verso-S': [' Verso-S'], \n",
    "    'Kadjar': [' Kadjar'], \n",
    "    'I80': [' I80'], \n",
    "    'Streetka': [' Streetka'],\n",
    "    'RS': [' RS'], \n",
    "    'I': [' i'], \n",
    "    'Ranger': [' Ranger'], \n",
    "    'IX2': [' IX2'], \n",
    "    'Escort': [' Escort'],\n",
    "    'Accent': [' Accent']\n",
    "}\n",
    "\n",
    "\n",
    "# Create a reverse lookup dictionary (each incorrect form maps to the correct one)\n",
    "replacement_dict = {variant: correct for correct, variants in correct_model.items() for variant in variants}\n",
    "\n",
    "# Replace incorrect brand names with the correct ones\n",
    "X_train[\"model\"] = X_train[\"model\"].replace(replacement_dict)\n",
    "X_val[\"model\"] = X_val[\"model\"].replace(replacement_dict)\n",
    "test_data[\"model\"] = test_data[\"model\"].replace(replacement_dict)\n",
    "\n",
    "# Verify the cleaning\n",
    "print(X_train[\"model\"].unique())\n",
    "print(X_val[\"model\"].unique())\n",
    "print(test_data[\"model\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81452f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##correcting spelling mistakes of 'transmission' for X_train, X_val and test_data\n",
    "\n",
    "correct_transmission = {\n",
    "    'Semi-Auto': ['Semi-Aut', 'semi-auto', 'emi-Auto', 'SEMI-AUTO', 'SEMI-AUT', 'EMI-AUTO', 'emi-Aut', 'emi-auto', 'semi-aut'],\n",
    "    'Manual': ['anual', 'manual', 'Manua', 'MANUAL', ' Manual ', 'ANUAL', 'manua', 'anua', 'MANUA', ' manual ', ' MANUAL ', ' Manual', 'Manual ', 'manual '],\n",
    "    'Automatic': ['AUTOMATIC', 'automatic', 'Automati', 'utomatic', 'UTOMATIC', 'automati', 'AUTOMATI', 'utomati'],\n",
    "}\n",
    "\n",
    "# Create a reverse lookup dictionary (each incorrect form maps to the correct one)\n",
    "replacement_dict = {variant: correct for correct, variants in correct_transmission.items() for variant in variants}\n",
    "\n",
    "# Replace incorrect brand names with the correct ones\n",
    "X_train[\"transmission\"] = X_train[\"transmission\"].replace(replacement_dict)\n",
    "X_val[\"transmission\"] = X_val[\"transmission\"].replace(replacement_dict)\n",
    "test_data[\"transmission\"] = test_data[\"transmission\"].replace(replacement_dict)\n",
    "\n",
    "#replacing the 'unknown' and 'other' variable with a missing value\n",
    "X_train[\"transmission\"] = X_train[\"transmission\"].replace(['unknow','UNKNOWN','nknown','nknow', 'unknown', 'Other'], np.nan)\n",
    "X_val[\"transmission\"] = X_val[\"transmission\"].replace(['unknow','UNKNOWN','nknown','nknow', 'unknown', 'Other'], np.nan)\n",
    "test_data[\"transmission\"] = test_data[\"transmission\"].replace(['unknow','UNKNOWN','nknown','nknow', 'unknown', 'Other'], np.nan)\n",
    "\n",
    "# Verify the cleaning\n",
    "print(X_train[\"transmission\"].unique())\n",
    "print(X_val[\"transmission\"].unique())\n",
    "print(test_data[\"transmission\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "##correcting spelling mistakes of 'fuelType' for X_train, X_val and test_data\n",
    "\n",
    "correct_fuelType = {\n",
    "    'Petrol': ['etrol', 'petrol', 'PETROL', 'Petro', 'petro', 'ETROL', 'PETRO', 'etro', 'ETRO'],\n",
    "    'Diesel': ['diesel','iesel','Diese','DIESEL','DIESE','IESEL','iese','diese','IESE'],\n",
    "    'Hybrid': ['HYBRID','ybri','Hybri','ybrid','hybrid','YBRID','HYBRI', 'hybri'],\n",
    "    'Other': ['ther','Othe','OTHER','other']\n",
    "}\n",
    "\n",
    "# Create a reverse lookup dictionary (each incorrect form maps to the correct one)\n",
    "replacement_dict = {variant: correct for correct, variants in correct_fuelType.items() for variant in variants}\n",
    "\n",
    "# Replace incorrect brand names with the correct ones\n",
    "X_train[\"fuelType\"] = X_train[\"fuelType\"].replace(replacement_dict)\n",
    "X_val[\"fuelType\"] = X_val[\"fuelType\"].replace(replacement_dict)\n",
    "test_data[\"fuelType\"] = test_data[\"fuelType\"].replace(replacement_dict)\n",
    "\n",
    "#replacing the 'other' variable with a missing value \n",
    "X_train[\"fuelType\"] = X_train[\"fuelType\"].replace(['ther','Othe','OTHER','other', 'Other'], np.nan)\n",
    "X_val[\"fuelType\"] = X_val[\"fuelType\"].replace(['ther','Othe','OTHER','other', 'Other'], np.nan)\n",
    "test_data[\"fuelType\"] = test_data[\"fuelType\"].replace(['ther','Othe','OTHER','other', 'Other'], np.nan)\n",
    "\n",
    "# Verify the cleaning\n",
    "print(X_train[\"fuelType\"].unique())\n",
    "print(X_val[\"fuelType\"].unique())\n",
    "print(test_data[\"fuelType\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595aedbf",
   "metadata": {},
   "source": [
    "##### 4.4.1.2. Check if the Models correspond to the Brand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94855e0",
   "metadata": {},
   "source": [
    "**Audi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17596cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of Audi for X_train\n",
    "audi = X_train[X_train['Brand'].str.lower() == 'audi']\n",
    "unique_audi_models = sorted(audi['model'].dropna().unique())\n",
    "unique_audi_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of Audi for X_val\n",
    "audi = X_val[X_val['Brand'].str.lower() == 'audi']\n",
    "unique_audi_models_v = sorted(audi['model'].dropna().unique())\n",
    "unique_audi_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095bb054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of Audi for test_data\n",
    "audi = test_data[test_data['Brand'].str.lower() == 'audi']\n",
    "unique_audi_models = sorted(audi['model'].dropna().unique())\n",
    "unique_audi_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ecac60",
   "metadata": {},
   "source": [
    "- All models seem to correspond to Audi cars, except for models 'A' and 'Q'. There are no models in Audi that are named 'A' and 'Q' solely, normally there are followed by a number, for example, 'A1' or 'Q3' as seen in the dataset. \n",
    "- Since it might be a problem of data collection, in a way that is missing a number after the letter, we have decided to replace these values by missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model 'A' by missing values\n",
    "X_train.loc[X_train[\"model\"] == 'A', \"model\"] = np.nan\n",
    "X_val.loc[X_val[\"model\"] == 'A', \"model\"] = np.nan\n",
    "test_data.loc[test_data[\"model\"] == 'A', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06411b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model 'Q' by missing values\n",
    "X_train.loc[X_train[\"model\"] == 'Q', \"model\"] = np.nan\n",
    "X_val.loc[X_val[\"model\"] == 'Q', \"model\"] = np.nan\n",
    "test_data.loc[test_data[\"model\"] == 'Q', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e257295",
   "metadata": {},
   "source": [
    "**BMW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'BMW' for X_train\n",
    "BMW = X_train[X_train['Brand'].str.lower() == 'bmw']\n",
    "unique_bmw_models = sorted(BMW['model'].dropna().unique())\n",
    "unique_bmw_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'BMW' for X_val\n",
    "BMW = X_val[X_val['Brand'].str.lower() == 'bmw']\n",
    "unique_bmw_models_v = sorted(BMW['model'].dropna().unique())\n",
    "unique_bmw_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'BMW' for test_data\n",
    "BMW = test_data[test_data['Brand'].str.lower() == 'bmw']\n",
    "unique_bmw_models = sorted(BMW['model'].dropna().unique())\n",
    "unique_bmw_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34340b5",
   "metadata": {},
   "source": [
    "- Similarly to 'Audi', in 'BMW' there are also models that should be followed by a number, which are 'X', 'Z', 'I' and 'M'.\n",
    "- Therefore, we are going to replace it by missing values, for the same reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc563f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model 'X' by missing values\n",
    "X_train.loc[X_train[\"model\"] == 'X', \"model\"] = np.nan\n",
    "X_val.loc[X_val[\"model\"] == 'X', \"model\"] = np.nan\n",
    "test_data.loc[test_data[\"model\"] == 'X', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b000abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model 'Z' by missing values\n",
    "X_train.loc[X_train[\"model\"] == 'Z', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcbc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model 'I' by missing values\n",
    "X_train.loc[X_train[\"model\"] == 'I', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model 'M' by missing values\n",
    "X_train.loc[X_train[\"model\"] == 'M', \"model\"] = np.nan\n",
    "X_val.loc[X_val[\"model\"] == 'M', \"model\"] = np.nan\n",
    "test_data.loc[test_data[\"model\"] == 'M', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ac30b",
   "metadata": {},
   "source": [
    "**Ford**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Ford' for X_train\n",
    "Ford = X_train[X_train['Brand'].str.lower() == 'ford']\n",
    "unique_ford_models = sorted(Ford['model'].dropna().unique())\n",
    "unique_ford_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d573ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Ford' for X_val\n",
    "Ford = X_val[X_val['Brand'].str.lower() == 'ford']\n",
    "unique_ford_models_v = sorted(Ford['model'].dropna().unique())\n",
    "unique_ford_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Ford' for test_data\n",
    "Ford = test_data[test_data['Brand'].str.lower() == 'ford']\n",
    "unique_ford_models_v = sorted(Ford['model'].dropna().unique())\n",
    "unique_ford_models_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3863e50",
   "metadata": {},
   "source": [
    "- All the models from the lists correspond to Ford models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd6bc1",
   "metadata": {},
   "source": [
    "**Hyundai**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8977ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Hyundai' for X_train\n",
    "Hyundai = X_train[X_train['Brand'].str.lower() == 'hyundai']\n",
    "unique_hyundai_models = sorted(Hyundai['model'].dropna().unique())\n",
    "unique_hyundai_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ef371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Hyundai' for X_train\n",
    "Hyundai = X_val[X_val['Brand'].str.lower() == 'hyundai']\n",
    "unique_hyundai_models_v = sorted(Hyundai['model'].dropna().unique())\n",
    "unique_hyundai_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b749047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Hyundai' for test_data\n",
    "Hyundai = test_data[test_data['Brand'].str.lower() == 'hyundai']\n",
    "unique_hyundai_models = sorted(Hyundai['model'].dropna().unique())\n",
    "unique_hyundai_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f632e",
   "metadata": {},
   "source": [
    "- Models 'Q2', 'Q3', 'Q5', 'Q7', 'A5' are from 'Audi' not from 'Hyundai'. There are no such models in Hyundai. \n",
    "- Here, since the number of observations where the brand is a hyundai and the model is either 'Q3', 'Q5', or 'Q7 is low, it was assumes it was a mistake of the brand name, so the brand was changed from 'Hyundai' to 'Audi'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b530155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Hyundai Q7 by Audi Q7 of X_train\n",
    "mask_train = (X_train[\"Brand\"] == \"Hyundai\") & (X_train[\"model\"] == \"Q7\")\n",
    "X_train.loc[mask_train, \"Brand\"] = \"Audi\"\n",
    "X_train.loc[mask_train, \"model\"] = \"Q7\"\n",
    "\n",
    "# Replace Hyundai Q3 by Audi Q3 of X_val\n",
    "mask_val = (X_val[\"Brand\"] == \"Hyundai\") & (X_val[\"model\"] == \"Q3\")\n",
    "X_val.loc[mask_val, \"Brand\"] = \"Audi\"\n",
    "X_val.loc[mask_val, \"model\"] = \"Q3\"\n",
    "\n",
    "# Replace Hyundai Q5 by Audi Q5 of X_val\n",
    "mask_val = (X_val[\"Brand\"] == \"Hyundai\") & (X_val[\"model\"] == \"Q5\")\n",
    "X_val.loc[mask_val, \"Brand\"] = \"Audi\"\n",
    "X_val.loc[mask_val, \"model\"] = \"Q5\"\n",
    "\n",
    "# Replace Hyundai A5 by Audi A5 of test_data\n",
    "mask_test = (test_data[\"Brand\"] == \"Hyundai\") & (test_data[\"model\"] == \"A5\")\n",
    "test_data.loc[mask_test, \"Brand\"] = \"Audi\"\n",
    "test_data.loc[mask_test, \"model\"] = \"A5\"\n",
    "\n",
    "# Replace Hyundai Q2 by Audi Q2 of test_data\n",
    "mask_test = (test_data[\"Brand\"] == \"Hyundai\") & (test_data[\"model\"] == \"Q2\")\n",
    "test_data.loc[mask_test, \"Brand\"] = \"Audi\"\n",
    "test_data.loc[mask_test, \"model\"] = \"Q2\"\n",
    "\n",
    "# Replace Hyundai Q3 by Audi Q3 of test_data\n",
    "mask_test = (test_data[\"Brand\"] == \"Hyundai\") & (test_data[\"model\"] == \"Q3\")\n",
    "test_data.loc[mask_test, \"Brand\"] = \"Audi\"\n",
    "test_data.loc[mask_test, \"model\"] = \"Q3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068a817",
   "metadata": {},
   "source": [
    "**Mercedes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256fc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Mercedes' for X_train\n",
    "Mercedes = X_train[X_train['Brand'].str.lower() == 'mercedes']\n",
    "unique_mercedes_models = sorted(Mercedes['model'].dropna().unique())\n",
    "unique_mercedes_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b195e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Mercedes' for X_val\n",
    "Mercedes = X_val[X_val['Brand'].str.lower() == 'mercedes']\n",
    "unique_mercedes_models_v = sorted(Mercedes['model'].dropna().unique())\n",
    "unique_mercedes_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd20a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Mercedes' for test_data\n",
    "Mercedes = test_data[test_data['Brand'].str.lower() == 'mercedes']\n",
    "unique_mercedes_models = sorted(Mercedes['model'].dropna().unique())\n",
    "unique_mercedes_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2931f96",
   "metadata": {},
   "source": [
    "- In Mercedes, 200, 220, 230 and 180 are not complete model names, they refer only to the engine/variant, not the class or body style. \n",
    "- Therefore, we have decided to replace them by missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model '230' by missing value of X_train\n",
    "X_train.loc[X_train[\"model\"] == '230', \"model\"] = np.nan\n",
    "\n",
    "#replacing model '200' by missing value of X_val\n",
    "X_val.loc[X_val[\"model\"] == '200', \"model\"] = np.nan\n",
    "\n",
    "#replacing model '220' by missing value of X_val\n",
    "X_val.loc[X_val[\"model\"] == '220', \"model\"] = np.nan\n",
    "\n",
    "#replacing model '180' by missing value of test_data\n",
    "test_data.loc[test_data[\"model\"] == '180', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eff62f",
   "metadata": {},
   "source": [
    "**Opel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Opel' for X_train\n",
    "Opel = X_train[X_train['Brand'].str.lower() == 'opel']\n",
    "unique_opel_models = sorted(Opel['model'].dropna().unique())\n",
    "unique_opel_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ece9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Opel' for X_val\n",
    "Opel = X_val[X_val['Brand'].str.lower() == 'opel']\n",
    "unique_opel_models_v = sorted(Opel['model'].dropna().unique())\n",
    "unique_opel_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Opel' for test_data\n",
    "Opel = test_data[test_data['Brand'].str.lower() == 'opel']\n",
    "unique_opel_models = sorted(Opel['model'].dropna().unique())\n",
    "unique_opel_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61c2a7",
   "metadata": {},
   "source": [
    "- 'Kadjar' is a 'Renault' model not a 'Opel' model.\n",
    "- Since the brand 'Renault' is not in our dataset, we have decided to replace this model by missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing model 'Kadjar' by missing value\n",
    "X_train.loc[X_train[\"model\"] == 'Kadjar', \"model\"] = np.nan\n",
    "X_val.loc[X_val[\"model\"] == 'Kadjar', \"model\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c016805a",
   "metadata": {},
   "source": [
    "**Skoda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4177c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Skoda' for X_train\n",
    "Skoda = X_train[X_train['Brand'].str.lower() == 'skoda']\n",
    "unique_skoda_models = sorted(Skoda['model'].dropna().unique())\n",
    "unique_skoda_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a80899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Skoda' for X_val\n",
    "Skoda = X_val[X_val['Brand'].str.lower() == 'skoda']\n",
    "unique_skoda_models_v = sorted(Skoda['model'].dropna().unique())\n",
    "unique_skoda_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'Skoda' for test_data\n",
    "Skoda = test_data[test_data['Brand'].str.lower() == 'skoda']\n",
    "unique_skoda_models = sorted(Skoda['model'].dropna().unique())\n",
    "unique_skoda_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04b613",
   "metadata": {},
   "source": [
    "- All the models showed seem to correspond to the brand 'Skoda'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198985d3",
   "metadata": {},
   "source": [
    "**VW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d352e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'VW' fro X_train\n",
    "VW = X_train[X_train['Brand'].str.lower() == 'vw']\n",
    "unique_vw_models = sorted(VW['model'].dropna().unique())\n",
    "unique_vw_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'VW' for X_val\n",
    "VW = X_val[X_val['Brand'].str.lower() == 'vw']\n",
    "unique_vw_models_v = sorted(VW['model'].dropna().unique())\n",
    "unique_vw_models_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ef3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the models of 'VW' for test_data\n",
    "VW = test_data[test_data['Brand'].str.lower() == 'vw']\n",
    "unique_vw_models = sorted(VW['model'].dropna().unique())\n",
    "unique_vw_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d10c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing 'Shara' by the correct name for test_data\n",
    "test_data.loc[test_data[\"model\"] == 'Shara', \"model\"] = 'Sharan'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3790bc0",
   "metadata": {},
   "source": [
    "- In x_train and X_val, all the models showed seem to correspond to the brand 'VW'.\n",
    "- In test_data, *Shara* is not the right VW model, the correct would be 'Sharan'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab33fc0",
   "metadata": {},
   "source": [
    "#### 4.4.2. Numerical Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03ffdc",
   "metadata": {},
   "source": [
    "##### 4.4.2.1. Correcting variables' incoherent values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c021c31",
   "metadata": {},
   "source": [
    "**Previous Owners**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f014dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative values for X_train\n",
    "X_train[X_train['previousOwners'] < 0]['previousOwners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733406ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative values for X_val \n",
    "X_val[X_val['previousOwners'] < 0]['previousOwners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative values for test_data\n",
    "test_data[test_data['previousOwners'] < 0]['previousOwners']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c571d",
   "metadata": {},
   "source": [
    "- The training dataset has 265 cars with negative owners and the validation set has 106, all equal to -2, which is not possible. - Since the mean value of the previousOwners is 1.994580 and the median is 2, we made the assumption that these negative values are spelling mistakes made during the data collection, that added the '-'. Therefore, we decided the change all of the negative values to positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the negative values by their module.\n",
    "X_train['previousOwners'] = X_train['previousOwners'].replace(-2, 2)\n",
    "X_val['previousOwners'] = X_val['previousOwners'].replace(-2, 2)\n",
    "test_data['previousOwners'] = test_data['previousOwners'].replace(-2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81a520",
   "metadata": {},
   "source": [
    "**Milage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for X_train \n",
    "X_train[X_train['mileage'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe061c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for X_val\n",
    "X_val[X_val['mileage'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42033bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for test_data\n",
    "test_data[test_data['mileage'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bc5616",
   "metadata": {},
   "source": [
    "- Here we have 247 negative values in the training set and 122 in the validation. \n",
    "- Since, it appers that these negative numbers do not have any kind of relationship, we decided to convert them into missing values to fill them in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab20fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing negative values by missing values \n",
    "X_train.loc[X_train[\"mileage\"] < 0, \"mileage\"] = np.nan\n",
    "X_val.loc[X_val[\"mileage\"] < 0, \"mileage\"] = np.nan\n",
    "test_data.loc[test_data[\"mileage\"] < 0, \"mileage\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363113f",
   "metadata": {},
   "source": [
    "**Mpg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for X_train \n",
    "X_train[X_train['mpg'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for X_val\n",
    "X_val[X_val['mpg'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6200ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for tes_data\n",
    "test_data[test_data['mpg'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c207823",
   "metadata": {},
   "source": [
    "- We can observe that negative values are all the same. In the context of the variable 'mpg', it is not normal to have dozens of cars with the exact same number of milles per gallon, since the car's consumption are dependent on a lot of factors such as the driver, the age of the car and the way the car is used. We have also noticed that all of the cars with negative values are BMWs, so it was probably an error related to the brand. \n",
    "- Therefore we decided to replace them with missing values to fill them afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing negative values by missing values \n",
    "X_train.loc[X_train[\"mpg\"] < 0, \"mpg\"] = np.nan\n",
    "X_val.loc[X_val[\"mpg\"] < 0, \"mpg\"] = np.nan\n",
    "test_data.loc[test_data[\"mpg\"] < 0, \"mpg\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ae420-ac24-4942-9c85-3204ecbc7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking electric cars for X_train\n",
    "X_train[X_train['fuelType'] == 'Electric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08faacb-c83b-4826-a92b-7f648d4a63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking electric cars for X_val\n",
    "X_val[X_val['fuelType'] == 'Electric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5149576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking electric cars for test_data\n",
    "test_data[test_data['fuelType'] == 'Electric']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58732124-0b11-4a9f-b989-435859135db8",
   "metadata": {},
   "source": [
    "- Also it does not make sense for an electric car to have the variable *mpg* since electric cars do not use petrol, so “miles per gallon” is meaningless.\n",
    "- Therefore, we have decided to replace *mpg* of electric cars by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f0c13-2ce7-41a1-8b84-be66285214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the mpg of electric cars to 0 for X_train and test_data\n",
    "X_train.loc[X_train['fuelType'] == 'Electric', 'mpg'] = 0\n",
    "test_data.loc[test_data['fuelType'] == 'Electric', 'mpg'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3db34",
   "metadata": {},
   "source": [
    "**Engine Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e597379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking obervations where mpg is lower than 0.5 for X_train \n",
    "X_train[X_train['engineSize'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57490837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking obervations where mpg is lower than 0.5 for X_val \n",
    "X_val[X_val['engineSize'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking obervations where mpg is lower than 0.5 for test_data \n",
    "test_data[test_data['engineSize'] < 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87bc41",
   "metadata": {},
   "source": [
    "- The negative values of EngineSize are all equal and they all belong to a ford. However, the model is different. It is not common for these models to have the same engine size, therefore, we have decided to replace by missing values. \n",
    "- In addition, we have rows where the value is less than 0.5. In those cases, the numbers are changed to missing values as it is highly unlikely to have cars with engine size smaller than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing negative values by missing values \n",
    "X_train.loc[X_train[\"engineSize\"] < 0.5, \"engineSize\"] = np.nan\n",
    "X_val.loc[X_val[\"engineSize\"] < 0.5, \"engineSize\"] = np.nan\n",
    "test_data.loc[test_data[\"engineSize\"] < 0.5, \"engineSize\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356c3cb",
   "metadata": {},
   "source": [
    "**Tax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eedc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for X_train \n",
    "X_train[X_train['tax'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for X_val\n",
    "X_val[X_val['tax'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking negative observations for test_data\n",
    "test_data[test_data['tax'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809fd33",
   "metadata": {},
   "source": [
    "- Even tough 'tax' has different values for different cars, it can never be negative, because that would mean the government is paying the owner to own the car, which is impossible. \n",
    "- We have decided to replace these values by missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing negative values by missing values \n",
    "X_train.loc[X_train[\"tax\"] < 0, \"tax\"] = np.nan\n",
    "X_val.loc[X_val[\"tax\"] < 0, \"tax\"] = np.nan\n",
    "test_data.loc[test_data[\"tax\"] < 0, \"tax\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa299a6",
   "metadata": {},
   "source": [
    "**Paint Quality (%)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f4e4b",
   "metadata": {},
   "source": [
    "- According to project guidelines, we should be able to \"create a predictive model capable of evaluating the price of a car based on the user’s input without needing the car to be taken to a mechanic.\"\n",
    "- As *paintQuality%* is \" The mechanic’s assessment of the cars’ overall paint quality and hull integrity (filled by the mechanic during evaluation).\", this variable is not considered valid and accurate to predict the model, so it would not be considered from now on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('paintQuality%', axis = 1, inplace = True)\n",
    "X_val.drop('paintQuality%', axis = 1, inplace = True)\n",
    "test_data.drop('paintQuality%', axis = 1, inplace = True)\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59242f92-fc91-4804-b883-c1a6e259653f",
   "metadata": {},
   "source": [
    "**Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b75229-d331-40a1-ac66-a10bbc06a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values higher than 2020 for X_train \n",
    "X_train[X_train['year'] > 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883298f-e6c1-46d2-b89e-614185b0eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values higher than 2020 for X_val \n",
    "X_val[X_val['year'] > 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2296147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values higher than 2020 for test_data\n",
    "test_data[test_data['year'] > 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfacaa4-cb55-4362-a6be-d195180a3aee",
   "metadata": {},
   "source": [
    "- Since the dataset we are analysing is from 2020, it does not make sense to have years after 2020. Noting that the only years that appear in the dataset after 2020 are 2023 and 2024.\n",
    "- Therefore, we have decided to replace these years by missing values, assumming there was an error in the system. These years could be 2013 and 2014 instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf76d8-c7cf-49c3-bc8e-51b8cd87fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing years after 2020 by missing values \n",
    "X_train.loc[X_train[\"year\"] > 2020, \"year\"] = np.nan\n",
    "X_val.loc[X_val[\"year\"] > 2020, \"year\"] = np.nan\n",
    "test_data.loc[test_data[\"year\"] > 2020, \"year\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5fcb5",
   "metadata": {},
   "source": [
    "### 4.5. Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d83906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking duplicates again after handling incoherencies on X_train\n",
    "int(X_train.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking duplicates again after handling incoherencies on X_val\n",
    "int(X_val.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49772a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping duplicate rows of X_train and X_val\n",
    "X_train = X_train.drop_duplicates()\n",
    "X_val = X_val.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8230fe8",
   "metadata": {},
   "source": [
    "### 4.6. Treating Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redifining metric features after not considering 'paintQuality%'\n",
    "metric_features = ['year', 'mileage', 'tax', 'mpg',\n",
    "                    'engineSize', 'previousOwners', 'hasDamage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking outliers again after handling incoherencies on X_train\n",
    "plot_multiple_boxplots(X_train, metric_features, title=\"Train Set: Numeric Variables' Box Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4142fd-e0bc-4960-90f0-d0f91ad1407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking outliers again after handling incoherencies on X_train\n",
    "plot_multiple_boxplots(X_val, metric_features, title=\"Train Set: Numeric Variables' Box Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking outliers again after handling incoherencies on test_data\n",
    "plot_multiple_boxplots(test_data, metric_features, title=\"Train Set: Numeric Variables' Box Plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cbf0d-5eb7-47a2-890b-85759764cd17",
   "metadata": {},
   "source": [
    "**Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train['year'] < 1995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[X_val['year'] < 1995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b88d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['year'] < 1995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing years before 1995 by missing values for X_train and test_data\n",
    "X_train.loc[X_train[\"year\"] < 1995, \"year\"] = np.nan\n",
    "test_data.loc[test_data[\"year\"] < 1995, \"year\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d2dbf",
   "metadata": {},
   "source": [
    "**Mileage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e35e38-3788-4163-a3d2-de1e18589b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train['mileage'] > 150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[X_val['mileage'] > 150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fadd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['mileage'] > 150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing mileages higher than 150000 by missing values\n",
    "X_train.loc[X_train[\"mileage\"] > 150000, \"mileage\"] = np.nan\n",
    "X_val.loc[X_val[\"mileage\"] > 150000, \"mileage\"] = np.nan\n",
    "test_data.loc[test_data[\"mileage\"] > 150000, \"mileage\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b3ae0-5ce5-4f35-a435-d473806012a1",
   "metadata": {},
   "source": [
    "**Tax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train['tax'] < 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95e390",
   "metadata": {},
   "source": [
    "- Since the number of cars with *tax* less than 100 is large, these we will not be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8da04-3635-4dc8-af51-58da445a5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the same as 400\n",
    "X_train[X_train['tax'] > 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290461ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[X_val['tax'] > 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40395093",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['tax'] > 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ed5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing taxes higher than 350 by missing values\n",
    "X_train.loc[X_train[\"tax\"] > 350, \"tax\"] = np.nan\n",
    "X_val.loc[X_val[\"tax\"] > 350, \"tax\"] = np.nan\n",
    "test_data.loc[test_data[\"tax\"] > 350, \"tax\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f9f37-5955-41c6-9213-b0eebb5f8a3b",
   "metadata": {},
   "source": [
    "**Mpg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307791ae-ff80-41d7-a7e4-30cb9c42fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train['mpg'] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[X_val['mpg'] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['mpg'] > 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20b846-bc4d-4463-bdf1-bdfdb27750a1",
   "metadata": {},
   "source": [
    "- All mpg > 300 are from BMW I3 and they all have the same mpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d680bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#replacing mpg higher than 300 by missing values\n",
    "X_train.loc[X_train[\"mpg\"] > 300, \"mpg\"] = np.nan\n",
    "X_val.loc[X_val[\"mpg\"] > 300, \"mpg\"] = np.nan\n",
    "test_data.loc[test_data[\"mpg\"] > 300, \"mpg\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3d88b-2caa-48da-9442-a92f6519cb26",
   "metadata": {},
   "source": [
    "**EngineSize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d02b05-3975-4ef7-89c5-20be81681669",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train['engineSize'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[X_val['engineSize'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[test_data['engineSize'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81488d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing mileages higher than 150000 by missing values\n",
    "X_train.loc[X_train[\"engineSize\"] > 5, \"engineSize\"] = np.nan\n",
    "X_val.loc[X_val[\"engineSize\"] > 5, \"engineSize\"] = np.nan\n",
    "test_data.loc[test_data[\"engineSize\"] > 5, \"engineSize\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab1940e",
   "metadata": {},
   "source": [
    "### 4.7. Treating Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19b9b4-d273-402d-9543-8e4e063aefcf",
   "metadata": {},
   "source": [
    "#### 4.7.1. Numerical Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fef6df-20c7-4e09-85d5-8396f0b2e8ed",
   "metadata": {},
   "source": [
    "**KNN Imputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2946b-f737-4d8e-8a43-17fb20d0df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbbf4a-dd5f-4d6b-ba70-47c3322d3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89966429",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ce19b-e0f4-4136-8d6c-47ee68cb8117",
   "metadata": {},
   "source": [
    "- Most of our variables are MAR (missing at random), which means that missingness depends on known variables. For example, we can imply that milage depends on brand, year and engine size; mpg depends on fuel type and model; tax depends on fuel type and year, etc.\n",
    "- This means that the \"correct\" value for a missing record would not reply on the global mean, but depends on similiar cars. Therefore, the KNN imputer method is a good solution for this type of problem since it is capable of dealing with MAR, while capturing non linear relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bec47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_encoding_brand = X_train['Brand'].value_counts()\n",
    "X_train['brand_encoded'] = X_train['Brand'].map(freq_encoding_brand)\n",
    "X_val['brand_encoded'] = X_val['Brand'].map(freq_encoding_brand)\n",
    "test_data['brand_encoded'] = test_data['Brand'].map(freq_encoding_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c412744",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_encoding_model = X_train['model'].value_counts()\n",
    "X_train['model_encoded'] = X_train['model'].map(freq_encoding_model)\n",
    "X_val['model_encoded'] = X_val['model'].map(freq_encoding_model)\n",
    "test_data['model_encoded'] = test_data['model'].map(freq_encoding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071532",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_encoding_transmission = X_train['transmission'].value_counts()\n",
    "X_train['transmission_encoded'] = X_train['transmission'].map(freq_encoding_transmission)\n",
    "X_val['transmission_encoded'] = X_val['transmission'].map(freq_encoding_transmission)\n",
    "test_data['transmission_encoded'] = test_data['transmission'].map(freq_encoding_transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[\"fuelType\"].value_counts())\n",
    "print(X_val[\"fuelType\"].value_counts())\n",
    "print(test_data[\"fuelType\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6edece",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_fuels = ['Electric', 'Other']\n",
    "X_train['fuelType'] = X_train['fuelType'].replace(rare_fuels, 'Other')\n",
    "X_val['fuelType'] = X_val['fuelType'].replace(rare_fuels, 'Other')\n",
    "test_data['fuelType'] = test_data['fuelType'].replace(rare_fuels, 'Other')\n",
    "\n",
    "freq_encoding_fuel = X_train['fuelType'].value_counts() \n",
    "X_train['fuelType_encoded'] = X_train['fuelType'].map(freq_encoding_fuel)\n",
    "X_val['fuelType_encoded'] = X_val['fuelType'].map(freq_encoding_fuel)\n",
    "test_data['fuelType_encoded'] = test_data['fuelType'].map(freq_encoding_fuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Brand', 'model', 'transmission', 'fuelType'], axis=1)\n",
    "X_val = X_val.drop(['Brand', 'model', 'transmission', 'fuelType'], axis=1)\n",
    "test_data = test_data.drop(['Brand', 'model', 'transmission', 'fuelType'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88437c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring that y_train has the same rows X_train\n",
    "y_train = y_train.loc[X_train.index]\n",
    "y_val = y_val.loc[X_val.index]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d68883-92df-4338-9f8b-22e532f3e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalling X_train and X_val since KNN imputer uses distances\n",
    "\n",
    "#numerical variables whose missing values need to be filled\n",
    "numeric_cols = ['tax', 'mpg', 'mileage', 'engineSize', 'hasDamage', 'previousOwners', 'year', 'model_encoded', 'brand_encoded', 'fuelType_encoded', 'transmission_encoded']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fitting the scaler only on training dataset (to avoid leakage)\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "\n",
    "# transforming validation dataset using the same scaling\n",
    "X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
    "test_data[numeric_cols] = scaler.transform(test_data[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a17be-c24e-471a-bfa4-c95d708407ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNImputer(n_neighbors=5, weights='distance')\n",
    "\n",
    "X_train[numeric_cols] = knn.fit_transform(X_train[numeric_cols])\n",
    "X_val[numeric_cols] = knn.transform(X_val[numeric_cols])\n",
    "test_data[numeric_cols] = knn.transform(test_data[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a939dc-2d3e-4d7b-9755-877a2ab3d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08839f-e059-4160-a1de-e1f76d07d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48696b-bbb2-43c0-9c04-7bab803e3c97",
   "metadata": {},
   "source": [
    "#### 4.7.2. Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1667a6-f8a9-4158-9e77-0b02986fb557",
   "metadata": {},
   "source": [
    "**Filling with the mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad74616-e885-4c10-befc-316c0cae348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[non_metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfa561-7e81-4153-9e48-c2dea3d72f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[non_metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff1cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[non_metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51cd7b-8db7-42ca-90f2-ce3a8d9ab239",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "X_train.loc[:, non_metric_features] = cat_imputer.fit_transform(X_train[non_metric_features])\n",
    "X_val.loc[:, non_metric_features] = cat_imputer.transform(X_val[non_metric_features])\n",
    "test_data.loc[:, non_metric_features] = cat_imputer.transform(test_data[non_metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b6bcd-3f21-4c6b-b1b8-2d0efa105d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[non_metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3213fb-996b-4f08-b893-8fea8c90c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[non_metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[non_metric_features].isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4b25d",
   "metadata": {},
   "source": [
    "### 4.8. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295e379-f5e7-4079-9ce2-6af6a3adf980",
   "metadata": {},
   "source": [
    "#### 4.8.1. Creating New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c261b1-7b50-4b72-820b-05f5e9cd1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['engineEfficiency'] = X_train['mpg'] / X_train['engineSize']\n",
    "X_val['engineEfficiency'] = X_val['mpg'] / X_val['engineSize']\n",
    "test_data['engineEfficiency'] = test_data['mpg'] / test_data['engineSize']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22885af1-fd75-4cdc-b86a-91515899dd4b",
   "metadata": {},
   "source": [
    "#### 4.8.2. Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a678a-b407-45ab-8a78-a5d525bfd1ca",
   "metadata": {},
   "source": [
    "- Frequency encoding is used to transform the variables Brand and model into numerical, as these have a high cardinality, while transmission and fuelType was transformed into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00474904-c375-40f5-a61c-0efe3e099d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_encoding_brand = X_train['Brand'].value_counts()\n",
    "mean_freq_brand = freq_encoding_brand.mean()\n",
    "X_train['brand_encoded'] = X_train['Brand'].map(freq_encoding_brand)\n",
    "X_val['brand_encoded'] = X_val['Brand'].map(freq_encoding_brand).fillna(mean_freq_brand)\n",
    "test_data['brand_encoded'] = test_data['Brand'].map(freq_encoding_brand).fillna(mean_freq_brand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d1587d-3a80-4b71-94fc-456641cabaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_encoding_model = X_train['model'].value_counts()\n",
    "mean_freq_model = freq_encoding_model.mean()\n",
    "X_train['model_encoded'] = X_train['model'].map(freq_encoding_model)\n",
    "X_val['model_encoded'] = X_val['model'].map(freq_encoding_model).fillna(mean_freq_model)\n",
    "test_data['model_encoded'] = test_data['model'].map(freq_encoding_model).fillna(mean_freq_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_encoding_transmission = X_train['transmission'].value_counts()\n",
    "mean_freq_transmission = freq_encoding_transmission.mean()\n",
    "X_train['transmission_encoded'] = X_train['transmission'].map(freq_encoding_transmission)\n",
    "X_val['transmission_encoded'] = X_val['transmission'].map(freq_encoding_transmission).fillna(mean_freq_transmission)\n",
    "test_data['transmission_encoded'] = test_data['transmission'].map(freq_encoding_transmission).fillna(mean_freq_transmission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9df968-d136-44a0-9bc5-5570b0fe8341",
   "metadata": {},
   "source": [
    "- We observed that the fuelType variable contained, only 4 Electric cars, which is an extremely low representation for a category, and 46 rows defined as \"other\". To prevent overfitting and unstable coefficients, these categories were grouped together into the Other class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5530144-5585-4dd2-babc-1b9cdb97a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[\"fuelType\"].value_counts())\n",
    "print(X_val[\"fuelType\"].value_counts())\n",
    "print(test_data[\"fuelType\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5447eaf-d960-49e7-b76e-a20034dace53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_fuels = ['Electric', 'Other']\n",
    "X_train['fuelType'] = X_train['fuelType'].replace(rare_fuels, 'Other')\n",
    "X_val['fuelType'] = X_val['fuelType'].replace(rare_fuels, 'Other')\n",
    "test_data['fuelType'] = test_data['fuelType'].replace(rare_fuels, 'Other')\n",
    "\n",
    "freq_encoding_fuel = X_train['fuelType'].value_counts() \n",
    "mean_freq_fuel = freq_encoding_fuel.mean()\n",
    "X_train['fuelType_encoded'] = X_train['fuelType'].map(freq_encoding_fuel)\n",
    "X_val['fuelType_encoded'] = X_val['fuelType'].map(freq_encoding_fuel).fillna(mean_freq_fuel)\n",
    "test_data['fuelType_encoded'] = test_data['fuelType'].map(freq_encoding_fuel).fillna(mean_freq_fuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc7271-442a-474c-9b85-1e0331f0f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e5514-6747-4f4e-b98a-8abfe9877865",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2aedd9-5386-42d7-8ca3-7280f6e319e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Brand', 'model', 'transmission', 'fuelType'], axis=1)\n",
    "X_val = X_val.drop(['Brand', 'model', 'transmission', 'fuelType'], axis=1)\n",
    "test_data = test_data.drop(['Brand', 'model', 'transmission', 'fuelType'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f526dc-d825-475e-a209-a1970bdd2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring that y_train has the same rows X_train\n",
    "y_train = y_train.loc[X_train.index]\n",
    "y_val = y_val.loc[X_val.index]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f1f70",
   "metadata": {},
   "source": [
    "### 4.9. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the variable created has some infinite values\n",
    "print(np.isinf(X_train[\"engineEfficiency\"]).sum())\n",
    "print(np.isinf(X_val[\"engineEfficiency\"]).sum())\n",
    "print(np.isinf(test_data[\"engineEfficiency\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c40bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace infinite by missing values\n",
    "X_train = X_train.replace({\"engineEfficiency\": {np.inf: np.nan, -np.inf: np.nan}})\n",
    "X_val = X_val.replace({\"engineEfficiency\": {np.inf: np.nan, -np.inf: np.nan}})\n",
    "test_data = test_data.replace({\"engineEfficiency\": {np.inf: np.nan, -np.inf: np.nan}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the missing values using the mean\n",
    "mean_engineEfficiency = X_train['engineEfficiency'].mean()\n",
    "X_train['engineEfficiency'] = X_train['engineEfficiency'].fillna(mean_engineEfficiency)\n",
    "X_val['engineEfficiency'] = X_val['engineEfficiency'].fillna(mean_engineEfficiency)\n",
    "test_data['engineEfficiency'] = test_data['engineEfficiency'].fillna(mean_engineEfficiency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80256d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e52c2",
   "metadata": {},
   "source": [
    "- We replaced the infinites by missing values and fill them because, if there were infinites in *engineEfficiency*, the scaled would not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables that are not scalled yet\n",
    "rest_var = [ 'engineEfficiency']\n",
    "\n",
    "# fitting the scaler only on training dataset (to avoid leakage)\n",
    "X_train[rest_var] = scaler.fit_transform(X_train[rest_var])\n",
    "\n",
    "# transforming validation dataset using the same scaling\n",
    "X_val[rest_var] = scaler.transform(X_val[rest_var])\n",
    "test_data[rest_var] = scaler.transform(test_data[rest_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if X_train and y_train have the same number of rows\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5752869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if X_val and y_val have the same number of rows\n",
    "print(\"X_val shape:\", X_train.shape)\n",
    "print(\"y_val shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd342e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d04b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9357cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42737b",
   "metadata": {},
   "source": [
    "### 4.10. Feature Selection\n",
    "\n",
    "In order to correctly predict the price of the cars in our test dataset, it is important to chose a group of features that would be sufficient relevant to train the model. The choice of what features to keep was taken based on the analysis of filter, wrapper and embedded methods. The filter methods developed were the *Variance*, the *Spearman Correlation Matrix* and the *Mutual Information (MI)*, while in terms of wrapper methods, the *RFECV* and the *Sequential Feature Selector* with *Forward Selection* were the two methods chosen. In addition, *Lasso* and *Random Forest Feature Importance* were also taken into consideration as part of embedded methods. \n",
    "We have decided to analyse and retrieving insights of each method individually and, at the end, grouping all information in one table, it is could be easier to understan what features should be kept. \n",
    "In feature selection, we are only going to consider *X_train* and *X_val*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d5991",
   "metadata": {},
   "source": [
    "#### 4.10.1. Filter Methods \n",
    "This methods are caracterized by being statistical approaches that do not consider any machine learning algorithm. Our objective is to compare our features against the target variable (*price*). However, these methods solely are not enough to conduct a good feature selection due to the fact that we are only looking to correlations between two variables at a time. There are cases where a variable can be \"jointly significant\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada58886",
   "metadata": {},
   "source": [
    "##### 4.10.1.1. Variance \n",
    "First, we looked at the variance of each variable to understand if there are variables whose variance is null or almost null. If a variable is null, it means it is irrelavant for training the model because all their observations are equal or similiar, not adding any new information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be79352",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4ed3c",
   "metadata": {},
   "source": [
    "As previously seen, *hasDamaged* has a variance of 0, which is an indicator that would not be kept in the model. None of the remain variables presents a variance near 0, so according to this method, all variables should be kept except for **hasDamaged**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd0762",
   "metadata": {},
   "source": [
    "##### 4.10.1.2. Spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4af1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_train and y_train into one dataframe\n",
    "df_train = X_train.copy()\n",
    "df_train['price'] = y_train.values  # ensure alignment\n",
    "\n",
    "# Compute Spearman correlation\n",
    "cor_spearman = df_train.corr(method='spearman')\n",
    "cor_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c044f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask for upper triangle\n",
    "mask = np.triu(np.ones_like(cor_spearman, dtype=bool))\n",
    "\n",
    "# White style\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "sns.heatmap(\n",
    "    cor_spearman,\n",
    "    mask=mask,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "\n",
    "plt.title(\"Correlation Matrix Including Price\", fontsize=18, pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d7291",
   "metadata": {},
   "source": [
    "As already seen in data exploration, the only two couple of features that have a high correlation (<|0.8|) are *mileage* vs *year* and *engineEfficiency* vs *engineSize*, which present a negative correlation of -0.79 and -0.90, respectively. It is important to note that, even though, \n",
    "these correlations are usually a signal of redundance, all of them have good correlations with *price* (either positives or negatives correlations), and correlation matrixes only give information about linear relationships, which, as seen before, do not have a high predominance in our dataset. For that reason, according to this analysis, this variables should be kept in our model.  \n",
    "In addition, *previousOwners*, *hasDamaged* and *fuelType_Other* has no correlation or very few correlation with other variables, including *price*. \n",
    "This indicates these features are not relevant to predict our target.\n",
    "Therefore, according to this method, all variables should be kept except for **hasDamaged** and **previousOwners**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bdad05",
   "metadata": {},
   "source": [
    "##### 4.10.1.3. Mutual Information (MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e94ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = mutual_info_regression(X_train, y_train, random_state=0)\n",
    "\n",
    "mi_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'MI_Score': mi_scores\n",
    "}).sort_values(by='MI_Score', ascending=False)\n",
    "\n",
    "print(mi_df.head(10))\n",
    "\n",
    "top_mi_features = mi_df.head(15)['Feature']\n",
    "X_train_mi = X_train[top_mi_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df = mi_df.sort_values(by='MI_Score', ascending=False).reset_index(drop=True)\n",
    "mi_df['MI_Score_norm'] = mi_df['MI_Score'] / mi_df['MI_Score'].max()\n",
    "\n",
    "# Plot clean MI curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mi_df['Feature'], mi_df['MI_Score_norm'], marker='o', color='steelblue', linewidth=2)\n",
    "plt.title(\"Mutual Information Scores — Feature Importance\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Feature\", fontsize=12)\n",
    "plt.ylabel(\"Normalized MI Score\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d65ddb",
   "metadata": {},
   "source": [
    "Considering that *Spearman Correlation Matrix* only analysis linear relationships, we have decided to perform the *Mutual Information (MI)* that gives us information about nonlinear predictive power of features. \n",
    "The MI scores show that *engineEfficiency* and *model_encode*d are the two most informative predictors, followed by *mpg*, *engineSize*, *year*, *brand_encoded* and *mileage*.\n",
    "After the top 7 features, the MI values either flatten considerably or the Normalized MI score is low (<0.4), indicating that additional variables give us little new information to predict *price*. \n",
    "Therefore, according to this method, the variables **previousOwners**, **hasDamaged**, **fuelType_encoded**, **transmission_encoded** and **tax** should not be consider when training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4ae46",
   "metadata": {},
   "source": [
    "#### 4.10.2. Wrapper Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed2418",
   "metadata": {},
   "source": [
    "##### 4.10.2.1. RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and validation datasets\n",
    "X_combined = np.concatenate([X_train, X_val])\n",
    "y_combined = np.concatenate([y_train, y_val])\n",
    "\n",
    "# Create a test fold index (-1 for train, 0 for validation)\n",
    "test_fold = [-1] * len(X_train) + [0] * len(X_val)\n",
    "\n",
    "print('Test fold: ', len(test_fold))\n",
    "print('X_combined: ', len(X_combined))\n",
    "print('y_combined: ', len(y_combined))\n",
    "\n",
    "# Define the PredefinedSplit\n",
    "ps = PredefinedSplit(test_fold=test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprune random forest\n",
    "\n",
    "base_estimator = RandomForestRegressor(\n",
    "    n_estimators=200,   # number of trees\n",
    "    max_depth=10,\n",
    "    min_samples_leaf = 4,\n",
    "    max_features=\"sqrt\",\n",
    "    min_impurity_decrease = 0.001,\n",
    "    random_state=0,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''base_estimator = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=10,\n",
    "    min_samples_split=12,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8cbfa",
   "metadata": {},
   "source": [
    "tentamos este, mas apesar de dar melhores resultados, estava a dar mais overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of features\n",
    "neg_mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# 3. Execute RFECV to find the optimal feature count based on Validation RMSE\n",
    "# Using the balanced estimator for the primary optimization process.\n",
    "rfecv_selector = RFECV(\n",
    "    estimator=base_estimator, \n",
    "    step=1,\n",
    "    cv=ps, # Uses the PredefinedSplit (X_val) for scoring\n",
    "    scoring=neg_mse_scorer\n",
    ")\n",
    "rfecv_selector.fit(X_combined, y_combined)\n",
    "\n",
    "# --- Define the range of features evaluated by RFECV (for the X-axis) ---\n",
    "feature_counts_range = rfecv_selector.cv_results_['n_features']\n",
    "\n",
    "# 4. Calculate Training RMSE for the plot (MANUAL LOOP CORRECTED)\n",
    "# We calculate the Training score for each feature subset size determined by the ranking.\n",
    "train_rmse_list = []\n",
    "feature_ranking = rfecv_selector.ranking_\n",
    "\n",
    "for n in feature_counts_range:\n",
    "    # Identify the features selected at this step (rank <= n)\n",
    "    selected_features_mask = feature_ranking <= n\n",
    "    \n",
    "    # Subset X_train using the mask, assuming X_train is a Pandas DataFrame.\n",
    "    X_train_subset = X_train.iloc[:, selected_features_mask]\n",
    "    \n",
    "    # Train on the SUBSET of features\n",
    "    base_estimator.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Predict and calculate Training RMSE on the SUBSET of features\n",
    "    train_pred = base_estimator.predict(X_train_subset)\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    train_rmse_list.append(np.sqrt(train_mse))\n",
    "\n",
    "\n",
    "# 5. Prepare Plotting Data and Output\n",
    "optimal_nof = rfecv_selector.n_features_\n",
    "validation_scores_neg_mse = rfecv_selector.cv_results_['mean_test_score']\n",
    "# Convert Validation Negative MSE scores to positive RMSE\n",
    "validation_rmse = np.sqrt(-validation_scores_neg_mse) \n",
    "# The index of the optimal number of features is optimal_nof - 1\n",
    "min_rmse = validation_rmse[optimal_nof - 1] \n",
    "\n",
    "# Variables for Plotting\n",
    "nof_list = feature_counts_range\n",
    "val_rmse_list = validation_rmse\n",
    "nof = optimal_nof\n",
    "low_rmse = min_rmse\n",
    "\n",
    "print(\"\\n--- RFECV Results (Using Random Forest) ---\")\n",
    "print(f\"Optimal number of features found: {nof}\")\n",
    "print(f\"Minimum Validation RMSE achieved: {low_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd61cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Training RMSE (NEWLY ADDED)\n",
    "plt.plot(nof_list, train_rmse_list,\n",
    "         label=\"RMSE on Training Set\", color='yellowgreen', linewidth=2) \n",
    "         \n",
    "# Validation RMSE\n",
    "plt.plot(nof_list, val_rmse_list, \n",
    "         label=\"RMSE on Validation Set\", color='dimgray', linewidth=2) \n",
    "\n",
    "# Highlight the optimal point\n",
    "plt.plot(nof, low_rmse, 'ro', \n",
    "         label=f'Optimal Features: {nof} (RMSE: {low_rmse:.4f})', markersize=8)\n",
    "\n",
    "plt.xlabel(\"Number of Features Selected\")\n",
    "plt.ylabel(\"RMSE (Root Mean Squared Error)\") \n",
    "plt.title(\"RFECV Performance: Training vs. Validation Error\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mask of selected features (True for selected, False otherwise)\n",
    "# rfecv_selector.support_ stores the mask corresponding to the optimal_nof\n",
    "selected_feature_mask = rfecv_selector.support_\n",
    "\n",
    "forward_features = X_train.columns[selected_feature_mask]\n",
    "\n",
    "print(\"Selected features using RFECV ({} features):\".format(optimal_nof))\n",
    "print(list(forward_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe82429",
   "metadata": {},
   "source": [
    "According to *RFECV* with *Random Forest* as estimator, the optimal number of features to keep would be 10 as this combination of features reveal the lowest validation RMSE. The minimum score was 3043.1847, indicating that the model’s average prediction error is about £2938.\n",
    "Therefore, according to this method, the variables to be discarded are **previousOwners** and **hasDamaged**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32816f",
   "metadata": {},
   "source": [
    "##### 4.10.2.2. Sequential Forward Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "#forward selection\n",
    "\n",
    "sfs_forward = SequentialFeatureSelector(\n",
    "    estimator=base_estimator,\n",
    "    n_features_to_select=\"auto\",   # Let SFS find optimal count\n",
    "    direction=\"forward\",\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=ps,                          # small CV to reduce compute\n",
    "    n_jobs=-1,\n",
    "    tol=1e-3  \n",
    ")\n",
    "\n",
    "sfs_forward.fit(X_combined, y_combined)\n",
    "\n",
    "# Selected feature mask and names\n",
    "forward_mask = sfs_forward.get_support()\n",
    "forward_features = X_train.columns[forward_mask]\n",
    "\n",
    "print(\"Forward Selected Features:\")\n",
    "print(list(forward_features))\n",
    "\n",
    "# Evaluate on validation set\n",
    "base_estimator.fit(X_train[forward_features], y_train)\n",
    "y_val_pred_forward = base_estimator.predict(X_val[forward_features])\n",
    "val_rmse_forward = np.sqrt(mean_squared_error(y_val, y_val_pred_forward))\n",
    "\n",
    "# Calculate Training RMSE \n",
    "y_train_pred_forward = base_estimator.predict(X_train[forward_features])\n",
    "train_rmse_forward = np.sqrt(mean_squared_error(y_train, y_train_pred_forward))\n",
    "\n",
    "print(\"Training RMSE (Forward SFS):\", train_rmse_forward)\n",
    "print(\"Validation RMSE (Forward SFS):\", val_rmse_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d99ab",
   "metadata": {},
   "source": [
    "In constract with *RFECV*, *Sequential Forward Feature Selection* stated that the optimal number of features would only be 5. \n",
    "Therefore, according to this method, the features that should be removed are **previousOwners**, **fuelType_encoded**, **hasDamaged**, **transmission_encoded**, **tax** and **mileage**, **engineSize**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3021e",
   "metadata": {},
   "source": [
    "##### 4.10.2.2. Sequential Backward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Selection\n",
    "sfs_backward = SequentialFeatureSelector(\n",
    "    estimator=base_estimator,\n",
    "    n_features_to_select=\"auto\", # Let SFS find optimal count\n",
    "    direction=\"backward\",        # Key change for Backward Selection\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=ps,                       # Use the same PredefinedSplit\n",
    "    n_jobs=-1,\n",
    "    tol=1e-3\n",
    ")\n",
    "\n",
    "sfs_backward.fit(X_combined, y_combined)\n",
    "\n",
    "# Selected feature mask and names\n",
    "backward_mask = sfs_backward.get_support()\n",
    "backward_features = X_train.columns[backward_mask] \n",
    "\n",
    "print(\"\\nBackward Selected Features:\")\n",
    "print(list(backward_features))\n",
    "\n",
    "# Evaluate on validation set\n",
    "# We must use a fresh fit of the base_estimator on the optimally selected features\n",
    "base_estimator.fit(X_train[backward_features], y_train)\n",
    "y_val_pred_backward = base_estimator.predict(X_val[backward_features])\n",
    "val_rmse_backward = np.sqrt(mean_squared_error(y_val, y_val_pred_backward))\n",
    "\n",
    "# Calculate Training RMSE \n",
    "y_train_pred_backward = base_estimator.predict(X_train[backward_features])\n",
    "train_rmse_backward = np.sqrt(mean_squared_error(y_train, y_train_pred_backward))\n",
    "\n",
    "print(\"Training RMSE (Backward SFS):\", train_rmse_backward)\n",
    "print(\"Validation RMSE (Backward SFS):\", val_rmse_backward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb6533",
   "metadata": {},
   "source": [
    "#### 4.10.3. Embedded Methods \n",
    "As a way of complementing filter and wrapper methods, we have decided to also analyse some embedded methods since learn which features best contribute to the accuracy of the model while the model is being created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c277c",
   "metadata": {},
   "source": [
    "##### 4.10.3. Random Forest Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_df = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": X_train.columns,\n",
    "        \"rf_importance\": rf.feature_importances_\n",
    "    })\n",
    "    .sort_values(\"rf_importance\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n===== Random Forest Feature Importance =====\\n\")\n",
    "print(rf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70057690",
   "metadata": {},
   "source": [
    "Unlikely wrapper methods, *Random Forest Feature Importance* does not directly give us a set of optimal features, it inform us how much each feature contributes to improving the model’s predictions by reducing the variance of the target variable (price). When analysing the output of *RFFI*, it is possible to understand that importance values are relative, all the features sum to 1.0. This indicates that, the features that contribute the most for model’s predictive power are *transmission_encoded*, *engineEfficiency* and *year* with 27%, 21.9% and 18.9%, respectively. According to this method, these are the features that are frequently used to split nodes across many trees and the one the model relies heavily on to make predictions. On the other hand, *hasDamaged*, *previousOwners* and *hasDamage* are the features used very little (or not at all) in the trees, which means they do not reduce the variance of price significantly. In order to decide what features to keep or discard based on this method, our reference number was 0.01, since every feature whose importance is below this value, does not add enough information to the model. Thus, based on this method, every feature should be kept except for **previousOwners**, **hasDamaged**, **fuelType_encoded** and **tax**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6538f6",
   "metadata": {},
   "source": [
    "### Final Insights\n",
    "Based on all the methods used and their individual conclusions, we have decided to build a table where for each feature, we analyse whether to keep or discard based on the method. Our approach to make this decision is based on whether the feature has 2 or more methods where was stated \"discard\". In case of having it 2 time, we would test the model with and without that feature, while the ones that have it more than 2 times would be automatically discarded. This implies that the features that have none or one \"discard\" are automatically included in the model. Moreover, considering that *RFECV* and *SFFS* are methods that provide an optimal number of features based on a specific set of variables, we have decided to also test the model with these groups of features, independently of the remain methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b4598",
   "metadata": {},
   "source": [
    "| Predictor            | Variance | Spearman Correlation| Mutual Information | RFECV (Random Forest) | SFFS  | SBFS  | RFFI | Decision              |\n",
    "|----------------------|----------|---------------|---------------------|----------|------------------------|-------------|--------------|------------------------|\n",
    "| *year*                 | Keep     | Keep           | Keep           | Keep     | Keep               | Keep        | Keep         | Include in the model   |\n",
    "| *mileage*              | Keep     | Keep           | Keep           | Keep     | Keep               | Keep        | Keep         | Include in the model   |\n",
    "| *tax*                  | Keep     | Keep           | Discard        | Keep     | Discard            | Discard     | Discard      | Discard   |\n",
    "| *mpg*                  | Keep     | Keep           | Keep           | Keep     | Keep               | Keep        | Keep         | Include in the model   |\n",
    "| *engineSize*           | Keep     | Keep           | Keep           | Keep     | Keep               | Keep        | Keep         | Include in the model   |\n",
    "| *engineEfficiency*     | Keep     | Keep           | Keep           | Keep     | Keep               | Keep        | Keep         | Include in the model   |\n",
    "| *brand_encoded*        | Keep     | Keep           | Keep           | Keep     | Keep               | Keep        | Keep         | Include in the model   |\n",
    "| *model_encoded*        | Keep     | Keep           | Keep           | Keep     | Keep               | Keep        | Keep         | Include in the model   |\n",
    "| *transmission_encoded* | Keep     | Keep           | Discard        | Keep     | Keep               | Keep        | Keep         | Try with and without |\n",
    "| *fuelType_encoded*     | Keep     | Keep           | Discard        | Keep     | Keep               | Keep        | Discard      | Discard    |\n",
    "| *previousOwners*       | Keep     | Discard        | Discard        | Discard  | Keep               | Discard     | Discard      | Discard    |\n",
    "| *hasDamage*            | Discard  | Discard        | Discard        | Discard  | Discard            | Keep        | Discard      | Discard    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2bfbf1",
   "metadata": {},
   "source": [
    "Based on our strategy, we will test the model with the following sets of features: \n",
    "- *year*, *mileage*, *mpg*, *engineSize*, *engineEfficiency*, *brand_encoded*, *model_encoded*, *transmission_encoded*, *tax*.\n",
    "- *year*, *mileage*, *mpg*, *engineSize*, *engineEfficiency*, *brand_encoded*, *model_encoded*, *transmission_encoded*\n",
    "- *year*, *mpg*, *engineEfficiency*, *brand_encoded*, *model_encoded*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
